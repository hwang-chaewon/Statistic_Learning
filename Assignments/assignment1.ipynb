{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment1_2070092황채원.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dil34lm2V1T6"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "import io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BB_0dFbHdrBg"
      },
      "source": [
        "# generating training dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "CHqtsBP8du2s",
        "outputId": "52df9926-e07a-4186-993c-66682100531f"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded_train = files.upload()\n",
        "uploaded_test = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-76ef7e13-625b-4f70-823b-569d8651b1f3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-76ef7e13-625b-4f70-823b-569d8651b1f3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Train_Data.txt to Train_Data.txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-721b2484-3a88-4b8b-892f-030edb68b1ff\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-721b2484-3a88-4b8b-892f-030edb68b1ff\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Test_Data.txt to Test_Data.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlNQjWYg-y6F"
      },
      "source": [
        "df_train = pd.read_csv(io.StringIO(uploaded_train['Train_Data.txt'].decode(\"utf-8\")), \n",
        "                       sep=',', names=['ID', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'class'], header=None)\n",
        "df_test = pd.read_csv(io.StringIO(uploaded_test['Test_Data.txt'].decode(\"utf-8\")), \n",
        "                       sep=',', names=['ID', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'class'], header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXYIBh9jw9Hq"
      },
      "source": [
        "## Feature Selection or Manipulation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsHFLJ9oulM2",
        "outputId": "99af17ec-100d-49c0-969d-031b762e0b1f"
      },
      "source": [
        "X = df_train[['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9']].replace({'?':0})\n",
        "\n",
        "print(X['x6'][20:30])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20    10\n",
            "21     7\n",
            "22     1\n",
            "23     0\n",
            "24     1\n",
            "25     7\n",
            "26     1\n",
            "27     1\n",
            "28     1\n",
            "29     1\n",
            "Name: x6, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOMJCtB1JBQP"
      },
      "source": [
        "y = df_train['class'].replace({2:0, 4:1})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9lcoaTsJn1E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d22851a2-5fae-4ea9-c16b-6d177e86b83b"
      },
      "source": [
        "from sklearn.svm import LinearSVC \n",
        "from sklearn.feature_selection import SelectFromModel \n",
        "X, y = X,y \n",
        "\n",
        "lsvc = LinearSVC(C=0.003, penalty=\"l1\", dual=False).fit(X, y) \n",
        "model = SelectFromModel(lsvc, prefit=True) \n",
        "X_new = model.transform(X) \n",
        "X_new.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(599, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMSoKrXwUc98",
        "outputId": "5ca0d486-49aa-4c55-a908-26a9b0933b4b"
      },
      "source": [
        "x_train = torch.Tensor(np.array([X['x2'], X['x6'],X['x8']]).astype(np.uint8)).t() \n",
        "print(x_train.shape)\n",
        "\n",
        "y_train = torch.Tensor(y).unsqueeze(1)\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([599, 3])\n",
            "torch.Size([599, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZbQkpxkhH6G"
      },
      "source": [
        "# Define model class\n",
        "z = w1*x1 + w2*x2 + w3*x3 ....  + w6*x6 + b  -> <br>\n",
        "y = a = sigma(z) -> <br>\n",
        "L(y_hat = a, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWDgg8yEhFMk",
        "outputId": "516c764e-7bdf-46c1-b420-544ce38f3113"
      },
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self, input_size, output_size):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(input_size, output_size)\n",
        "\n",
        "  def forward(self, x): \n",
        "    pred = torch.sigmoid(self.linear(x))\n",
        "    return pred  \n",
        "\n",
        "  def predict(self, x):\n",
        "    pred = self.forward(x)\n",
        "    if pred >= 0.5:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "print(x_train.shape)\n",
        "\n",
        "torch.manual_seed(1)\n",
        "model = LogisticRegression(x_train.shape[1], 1)\n",
        "print(list(model.parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([599, 3])\n",
            "[Parameter containing:\n",
            "tensor([[ 0.2975, -0.2548, -0.1119]], requires_grad=True), Parameter containing:\n",
            "tensor([0.2710], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08wLbfEljkE8"
      },
      "source": [
        "# function to get model parameters (w1, w2, b)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJX7kArljiPZ",
        "outputId": "f014ee6d-4b71-4713-8a5a-fc1d0616ccdf"
      },
      "source": [
        "[w, b] = model.parameters()\n",
        "print(w) \n",
        "w1, w2,w3= w.view(x_train.shape[1])\n",
        "\n",
        "def get_params():\n",
        "  return (w1.item(), w2.item(),w3.item(), b[0].item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.2975, -0.2548, -0.1119]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gkj4yqKlgcA"
      },
      "source": [
        "# training the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkW2eQbklixb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c4ed392-f1de-4161-ee00-aab017236661"
      },
      "source": [
        "criterion = nn.BCELoss() \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "epochs = 300\n",
        "losses = []\n",
        "\n",
        "for i in range(epochs):\n",
        "  y_pred = model.forward(x_train)\n",
        "\n",
        "  loss = criterion(y_pred, y_train)\n",
        "\n",
        "  l_lambda = 0.1\n",
        "  l_reg = torch.tensor(0.)\n",
        "  for param in model.parameters():\n",
        "      l_reg += torch.norm(param) \n",
        "  loss += l_lambda * l_reg\n",
        "\n",
        "  print(\"epoch: \", i, \"loss: \", loss.item())\n",
        "  losses.append(loss.item())\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0 loss:  0.967048168182373\n",
            "epoch:  1 loss:  0.9332749247550964\n",
            "epoch:  2 loss:  0.8825355768203735\n",
            "epoch:  3 loss:  0.8356207609176636\n",
            "epoch:  4 loss:  0.8058540225028992\n",
            "epoch:  5 loss:  0.7938900589942932\n",
            "epoch:  6 loss:  0.7924759387969971\n",
            "epoch:  7 loss:  0.7935124635696411\n",
            "epoch:  8 loss:  0.7913891077041626\n",
            "epoch:  9 loss:  0.7832435369491577\n",
            "epoch:  10 loss:  0.7682748436927795\n",
            "epoch:  11 loss:  0.7470915913581848\n",
            "epoch:  12 loss:  0.7212886810302734\n",
            "epoch:  13 loss:  0.693178653717041\n",
            "epoch:  14 loss:  0.6655459403991699\n",
            "epoch:  15 loss:  0.6469318270683289\n",
            "epoch:  16 loss:  0.6354278326034546\n",
            "epoch:  17 loss:  0.6302128434181213\n",
            "epoch:  18 loss:  0.6293783783912659\n",
            "epoch:  19 loss:  0.629397451877594\n",
            "epoch:  20 loss:  0.6269255876541138\n",
            "epoch:  21 loss:  0.6205782294273376\n",
            "epoch:  22 loss:  0.611376941204071\n",
            "epoch:  23 loss:  0.6017131209373474\n",
            "epoch:  24 loss:  0.5937731266021729\n",
            "epoch:  25 loss:  0.5885441303253174\n",
            "epoch:  26 loss:  0.5857882499694824\n",
            "epoch:  27 loss:  0.5845861434936523\n",
            "epoch:  28 loss:  0.5839076042175293\n",
            "epoch:  29 loss:  0.5829551219940186\n",
            "epoch:  30 loss:  0.5812867283821106\n",
            "epoch:  31 loss:  0.5788058638572693\n",
            "epoch:  32 loss:  0.5756861567497253\n",
            "epoch:  33 loss:  0.5722687840461731\n",
            "epoch:  34 loss:  0.5689499974250793\n",
            "epoch:  35 loss:  0.5660693645477295\n",
            "epoch:  36 loss:  0.5638179183006287\n",
            "epoch:  37 loss:  0.5621878504753113\n",
            "epoch:  38 loss:  0.5609872341156006\n",
            "epoch:  39 loss:  0.5599203109741211\n",
            "epoch:  40 loss:  0.5587068200111389\n",
            "epoch:  41 loss:  0.5571860074996948\n",
            "epoch:  42 loss:  0.5553591847419739\n",
            "epoch:  43 loss:  0.5533595085144043\n",
            "epoch:  44 loss:  0.5513733625411987\n",
            "epoch:  45 loss:  0.5495591759681702\n",
            "epoch:  46 loss:  0.547997236251831\n",
            "epoch:  47 loss:  0.5466825366020203\n",
            "epoch:  48 loss:  0.5455486178398132\n",
            "epoch:  49 loss:  0.5445038676261902\n",
            "epoch:  50 loss:  0.5434653759002686\n",
            "epoch:  51 loss:  0.5423803925514221\n",
            "epoch:  52 loss:  0.5412328839302063\n",
            "epoch:  53 loss:  0.5400399565696716\n",
            "epoch:  54 loss:  0.5388396978378296\n",
            "epoch:  55 loss:  0.5376754403114319\n",
            "epoch:  56 loss:  0.536581814289093\n",
            "epoch:  57 loss:  0.5355756878852844\n",
            "epoch:  58 loss:  0.5346527695655823\n",
            "epoch:  59 loss:  0.5337921380996704\n",
            "epoch:  60 loss:  0.5329649448394775\n",
            "epoch:  61 loss:  0.53214430809021\n",
            "epoch:  62 loss:  0.5313136577606201\n",
            "epoch:  63 loss:  0.5304696559906006\n",
            "epoch:  64 loss:  0.5296205282211304\n",
            "epoch:  65 loss:  0.5287808775901794\n",
            "epoch:  66 loss:  0.5279654860496521\n",
            "epoch:  67 loss:  0.527184247970581\n",
            "epoch:  68 loss:  0.5264402627944946\n",
            "epoch:  69 loss:  0.5257301926612854\n",
            "epoch:  70 loss:  0.5250464081764221\n",
            "epoch:  71 loss:  0.5243799686431885\n",
            "epoch:  72 loss:  0.5237239003181458\n",
            "epoch:  73 loss:  0.5230739712715149\n",
            "epoch:  74 loss:  0.5224295258522034\n",
            "epoch:  75 loss:  0.5217928290367126\n",
            "epoch:  76 loss:  0.5211676359176636\n",
            "epoch:  77 loss:  0.5205576419830322\n",
            "epoch:  78 loss:  0.5199654698371887\n",
            "epoch:  79 loss:  0.5193917751312256\n",
            "epoch:  80 loss:  0.5188354253768921\n",
            "epoch:  81 loss:  0.5182940363883972\n",
            "epoch:  82 loss:  0.5177648663520813\n",
            "epoch:  83 loss:  0.517245352268219\n",
            "epoch:  84 loss:  0.5167338848114014\n",
            "epoch:  85 loss:  0.516230046749115\n",
            "epoch:  86 loss:  0.5157344341278076\n",
            "epoch:  87 loss:  0.5152477622032166\n",
            "epoch:  88 loss:  0.5147712230682373\n",
            "epoch:  89 loss:  0.514305591583252\n",
            "epoch:  90 loss:  0.5138510465621948\n",
            "epoch:  91 loss:  0.5134070515632629\n",
            "epoch:  92 loss:  0.5129731297492981\n",
            "epoch:  93 loss:  0.5125480890274048\n",
            "epoch:  94 loss:  0.5121314525604248\n",
            "epoch:  95 loss:  0.5117223262786865\n",
            "epoch:  96 loss:  0.5113204717636108\n",
            "epoch:  97 loss:  0.5109261274337769\n",
            "epoch:  98 loss:  0.510539174079895\n",
            "epoch:  99 loss:  0.5101599097251892\n",
            "epoch:  100 loss:  0.5097885131835938\n",
            "epoch:  101 loss:  0.5094249248504639\n",
            "epoch:  102 loss:  0.50906902551651\n",
            "epoch:  103 loss:  0.5087206363677979\n",
            "epoch:  104 loss:  0.5083792805671692\n",
            "epoch:  105 loss:  0.5080446004867554\n",
            "epoch:  106 loss:  0.5077163577079773\n",
            "epoch:  107 loss:  0.5073943734169006\n",
            "epoch:  108 loss:  0.5070784091949463\n",
            "epoch:  109 loss:  0.5067683458328247\n",
            "epoch:  110 loss:  0.506464421749115\n",
            "epoch:  111 loss:  0.506166398525238\n",
            "epoch:  112 loss:  0.5058741569519043\n",
            "epoch:  113 loss:  0.5055878162384033\n",
            "epoch:  114 loss:  0.5053070783615112\n",
            "epoch:  115 loss:  0.5050317645072937\n",
            "epoch:  116 loss:  0.504761815071106\n",
            "epoch:  117 loss:  0.5044969320297241\n",
            "epoch:  118 loss:  0.5042370557785034\n",
            "epoch:  119 loss:  0.5039820075035095\n",
            "epoch:  120 loss:  0.5037317872047424\n",
            "epoch:  121 loss:  0.5034862160682678\n",
            "epoch:  122 loss:  0.5032452940940857\n",
            "epoch:  123 loss:  0.5030089616775513\n",
            "epoch:  124 loss:  0.502777099609375\n",
            "epoch:  125 loss:  0.5025496482849121\n",
            "epoch:  126 loss:  0.5023264288902283\n",
            "epoch:  127 loss:  0.5021075010299683\n",
            "epoch:  128 loss:  0.5018925666809082\n",
            "epoch:  129 loss:  0.5016816258430481\n",
            "epoch:  130 loss:  0.5014746189117432\n",
            "epoch:  131 loss:  0.5012714862823486\n",
            "epoch:  132 loss:  0.5010720491409302\n",
            "epoch:  133 loss:  0.5008763670921326\n",
            "epoch:  134 loss:  0.5006842613220215\n",
            "epoch:  135 loss:  0.5004957318305969\n",
            "epoch:  136 loss:  0.5003105998039246\n",
            "epoch:  137 loss:  0.500128984451294\n",
            "epoch:  138 loss:  0.49995070695877075\n",
            "epoch:  139 loss:  0.49977564811706543\n",
            "epoch:  140 loss:  0.49960383772850037\n",
            "epoch:  141 loss:  0.4994351863861084\n",
            "epoch:  142 loss:  0.4992695152759552\n",
            "epoch:  143 loss:  0.4991069436073303\n",
            "epoch:  144 loss:  0.4989473819732666\n",
            "epoch:  145 loss:  0.49879056215286255\n",
            "epoch:  146 loss:  0.4986366927623749\n",
            "epoch:  147 loss:  0.4984855055809021\n",
            "epoch:  148 loss:  0.4983372092247009\n",
            "epoch:  149 loss:  0.4981915354728699\n",
            "epoch:  150 loss:  0.49804842472076416\n",
            "epoch:  151 loss:  0.4979078769683838\n",
            "epoch:  152 loss:  0.49776989221572876\n",
            "epoch:  153 loss:  0.4976344406604767\n",
            "epoch:  154 loss:  0.49750131368637085\n",
            "epoch:  155 loss:  0.4973706007003784\n",
            "epoch:  156 loss:  0.497242271900177\n",
            "epoch:  157 loss:  0.49711620807647705\n",
            "epoch:  158 loss:  0.49699240922927856\n",
            "epoch:  159 loss:  0.49687066674232483\n",
            "epoch:  160 loss:  0.49675121903419495\n",
            "epoch:  161 loss:  0.4966338872909546\n",
            "epoch:  162 loss:  0.4965185523033142\n",
            "epoch:  163 loss:  0.49640530347824097\n",
            "epoch:  164 loss:  0.4962940216064453\n",
            "epoch:  165 loss:  0.496184766292572\n",
            "epoch:  166 loss:  0.49607735872268677\n",
            "epoch:  167 loss:  0.4959719181060791\n",
            "epoch:  168 loss:  0.4958682656288147\n",
            "epoch:  169 loss:  0.4957664906978607\n",
            "epoch:  170 loss:  0.4956664443016052\n",
            "epoch:  171 loss:  0.495568186044693\n",
            "epoch:  172 loss:  0.4954715967178345\n",
            "epoch:  173 loss:  0.4953766465187073\n",
            "epoch:  174 loss:  0.49528348445892334\n",
            "epoch:  175 loss:  0.4951918125152588\n",
            "epoch:  176 loss:  0.4951018691062927\n",
            "epoch:  177 loss:  0.49501341581344604\n",
            "epoch:  178 loss:  0.49492645263671875\n",
            "epoch:  179 loss:  0.4948410093784332\n",
            "epoch:  180 loss:  0.4947570860385895\n",
            "epoch:  181 loss:  0.4946745038032532\n",
            "epoch:  182 loss:  0.49459344148635864\n",
            "epoch:  183 loss:  0.4945138096809387\n",
            "epoch:  184 loss:  0.49443548917770386\n",
            "epoch:  185 loss:  0.49435850977897644\n",
            "epoch:  186 loss:  0.4942827820777893\n",
            "epoch:  187 loss:  0.49420851469039917\n",
            "epoch:  188 loss:  0.49413537979125977\n",
            "epoch:  189 loss:  0.4940635561943054\n",
            "epoch:  190 loss:  0.49399298429489136\n",
            "epoch:  191 loss:  0.4939235746860504\n",
            "epoch:  192 loss:  0.4938552975654602\n",
            "epoch:  193 loss:  0.4937882423400879\n",
            "epoch:  194 loss:  0.4937223196029663\n",
            "epoch:  195 loss:  0.49365752935409546\n",
            "epoch:  196 loss:  0.49359381198883057\n",
            "epoch:  197 loss:  0.4935312271118164\n",
            "epoch:  198 loss:  0.4934696555137634\n",
            "epoch:  199 loss:  0.49340909719467163\n",
            "epoch:  200 loss:  0.493349552154541\n",
            "epoch:  201 loss:  0.49329107999801636\n",
            "epoch:  202 loss:  0.4932335615158081\n",
            "epoch:  203 loss:  0.4931770861148834\n",
            "epoch:  204 loss:  0.4931214451789856\n",
            "epoch:  205 loss:  0.4930667281150818\n",
            "epoch:  206 loss:  0.4930129647254944\n",
            "epoch:  207 loss:  0.4929601550102234\n",
            "epoch:  208 loss:  0.492908239364624\n",
            "epoch:  209 loss:  0.4928571283817291\n",
            "epoch:  210 loss:  0.49280691146850586\n",
            "epoch:  211 loss:  0.49275749921798706\n",
            "epoch:  212 loss:  0.49270886182785034\n",
            "epoch:  213 loss:  0.49266117811203003\n",
            "epoch:  214 loss:  0.49261415004730225\n",
            "epoch:  215 loss:  0.4925679564476013\n",
            "epoch:  216 loss:  0.49252253770828247\n",
            "epoch:  217 loss:  0.49247777462005615\n",
            "epoch:  218 loss:  0.49243390560150146\n",
            "epoch:  219 loss:  0.4923906922340393\n",
            "epoch:  220 loss:  0.49234816431999207\n",
            "epoch:  221 loss:  0.4923064112663269\n",
            "epoch:  222 loss:  0.4922652840614319\n",
            "epoch:  223 loss:  0.49222487211227417\n",
            "epoch:  224 loss:  0.4921850860118866\n",
            "epoch:  225 loss:  0.49214598536491394\n",
            "epoch:  226 loss:  0.4921075701713562\n",
            "epoch:  227 loss:  0.49206972122192383\n",
            "epoch:  228 loss:  0.492032527923584\n",
            "epoch:  229 loss:  0.4919958710670471\n",
            "epoch:  230 loss:  0.49195989966392517\n",
            "epoch:  231 loss:  0.491924524307251\n",
            "epoch:  232 loss:  0.4918896555900574\n",
            "epoch:  233 loss:  0.4918554425239563\n",
            "epoch:  234 loss:  0.4918217062950134\n",
            "epoch:  235 loss:  0.4917885661125183\n",
            "epoch:  236 loss:  0.49175596237182617\n",
            "epoch:  237 loss:  0.49172383546829224\n",
            "epoch:  238 loss:  0.49169233441352844\n",
            "epoch:  239 loss:  0.49166131019592285\n",
            "epoch:  240 loss:  0.4916307330131531\n",
            "epoch:  241 loss:  0.49160072207450867\n",
            "epoch:  242 loss:  0.49157118797302246\n",
            "epoch:  243 loss:  0.49154210090637207\n",
            "epoch:  244 loss:  0.4915134608745575\n",
            "epoch:  245 loss:  0.4914853572845459\n",
            "epoch:  246 loss:  0.49145764112472534\n",
            "epoch:  247 loss:  0.491430401802063\n",
            "epoch:  248 loss:  0.49140363931655884\n",
            "epoch:  249 loss:  0.49137723445892334\n",
            "epoch:  250 loss:  0.4913513660430908\n",
            "epoch:  251 loss:  0.4913257956504822\n",
            "epoch:  252 loss:  0.49130064249038696\n",
            "epoch:  253 loss:  0.4912759065628052\n",
            "epoch:  254 loss:  0.491251677274704\n",
            "epoch:  255 loss:  0.49122774600982666\n",
            "epoch:  256 loss:  0.4912042021751404\n",
            "epoch:  257 loss:  0.49118107557296753\n",
            "epoch:  258 loss:  0.49115830659866333\n",
            "epoch:  259 loss:  0.491135835647583\n",
            "epoch:  260 loss:  0.4911137521266937\n",
            "epoch:  261 loss:  0.49109211564064026\n",
            "epoch:  262 loss:  0.49107077717781067\n",
            "epoch:  263 loss:  0.4910496771335602\n",
            "epoch:  264 loss:  0.4910290837287903\n",
            "epoch:  265 loss:  0.4910086989402771\n",
            "epoch:  266 loss:  0.4909886121749878\n",
            "epoch:  267 loss:  0.4909689426422119\n",
            "epoch:  268 loss:  0.4909495711326599\n",
            "epoch:  269 loss:  0.4909304976463318\n",
            "epoch:  270 loss:  0.4909116327762604\n",
            "epoch:  271 loss:  0.4908931851387024\n",
            "epoch:  272 loss:  0.4908750057220459\n",
            "epoch:  273 loss:  0.4908571243286133\n",
            "epoch:  274 loss:  0.49083948135375977\n",
            "epoch:  275 loss:  0.4908221364021301\n",
            "epoch:  276 loss:  0.490805059671402\n",
            "epoch:  277 loss:  0.4907882809638977\n",
            "epoch:  278 loss:  0.49077171087265015\n",
            "epoch:  279 loss:  0.49075549840927124\n",
            "epoch:  280 loss:  0.49073952436447144\n",
            "epoch:  281 loss:  0.49072378873825073\n",
            "epoch:  282 loss:  0.49070826172828674\n",
            "epoch:  283 loss:  0.49069297313690186\n",
            "epoch:  284 loss:  0.49067795276641846\n",
            "epoch:  285 loss:  0.49066317081451416\n",
            "epoch:  286 loss:  0.49064862728118896\n",
            "epoch:  287 loss:  0.4906342625617981\n",
            "epoch:  288 loss:  0.4906201958656311\n",
            "epoch:  289 loss:  0.4906063675880432\n",
            "epoch:  290 loss:  0.49059268832206726\n",
            "epoch:  291 loss:  0.490579217672348\n",
            "epoch:  292 loss:  0.4905659854412079\n",
            "epoch:  293 loss:  0.49055296182632446\n",
            "epoch:  294 loss:  0.49054014682769775\n",
            "epoch:  295 loss:  0.49052757024765015\n",
            "epoch:  296 loss:  0.49051517248153687\n",
            "epoch:  297 loss:  0.49050289392471313\n",
            "epoch:  298 loss:  0.4904908537864685\n",
            "epoch:  299 loss:  0.4904789924621582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "rYkUBuB2lfiU",
        "outputId": "c562dd59-7b9c-420d-94a3-bcdefed2689f"
      },
      "source": [
        "plt.plot(range(epochs), losses)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80NQ8m48n8fM"
      },
      "source": [
        "# model evalation with new datasets the model has never seen before"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReUhXQhwFygw",
        "outputId": "9e0ecabc-0a30-49a7-e39c-d7d9d4fc8755"
      },
      "source": [
        "X_test = df_test[['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9']].replace({'?':0})\n",
        "Y_test = df_test['class'].replace({2:0, 4:1})\n",
        "\n",
        "x_test = torch.Tensor(np.array([X_test['x2'], X_test['x6'],X_test['x8']]).astype(np.uint8)).t() \n",
        "print(x_test.shape)\n",
        "y_test = torch.Tensor(Y_test).unsqueeze(1)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 3])\n",
            "torch.Size([100, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZcMsmzQHERY",
        "outputId": "0312ac7c-a093-4aff-a389-1e0f5f4ea59e"
      },
      "source": [
        "no_correct = 0\n",
        "for i in range(len(x_train)):\n",
        "  if model.predict(x_train[i]) == y_train[i]:\n",
        "    no_correct += 1\n",
        "\n",
        "accuracy = no_correct/len(x_train)*100\n",
        "print(\"Predcition accuracy_train= {}%\".format(accuracy))\n",
        "\n",
        "no_correct_test=0\n",
        "for i in range(len(x_test)):\n",
        "  if model.predict(x_test[i]) == y_test[i]:\n",
        "    no_correct_test += 1\n",
        "\n",
        "accuracy = no_correct_test/len(x_test)*100\n",
        "\n",
        "print(\"Predcition accuracy_test= {}%\".format(accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predcition accuracy_train= 95.32554257095158%\n",
            "Predcition accuracy_test= 100.0%\n"
          ]
        }
      ]
    }
  ]
}